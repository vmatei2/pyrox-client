{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HYROX race analytics pyrox-client A Python client for HYROX race results that keeps analysis fast, reliable, and reproducible. Pull full races as pandas DataFrames, apply rigorous filters, and build high-signal performance models. Get started Analytics Clean race pulls Download race data straight from the CDN and cache it locally for repeatable work. Clear filters Server-side gender and division filters plus exact time-window slicing in minutes. Analysis ready Station and run splits are already renamed and normalized for modeling. Quickstart \u00b6 import pyrox client = pyrox . PyroxClient () races = client . list_races ( season = 7 ) print ( races . head ()) london = client . get_race ( season = 7 , location = \"london\" , gender = \"male\" ) print ( london [ \"total_time\" ] . describe ()) Use this documentation as a map: start with Quickstart, then move into Filtering, Data Model, and the Analytics page once you are ready to dive into your data/performance.","title":"Home"},{"location":"#quickstart","text":"import pyrox client = pyrox . PyroxClient () races = client . list_races ( season = 7 ) print ( races . head ()) london = client . get_race ( season = 7 , location = \"london\" , gender = \"male\" ) print ( london [ \"total_time\" ] . describe ()) Use this documentation as a map: start with Quickstart, then move into Filtering, Data Model, and the Analytics page once you are ready to dive into your data/performance.","title":"Quickstart"},{"location":"analytics/","text":"Analytics \u00b6 A focused set of workflows to extract signal from race data. 1. Segment z-scores \u00b6 Normalize each station split relative to the field to see strengths and weaknesses. import numpy as np import pandas as pd race = client . get_race ( season = 7 , location = \"london\" , gender = \"male\" ) split_cols = [ \"skiErg_time\" , \"sledPush_time\" , \"sledPull_time\" , \"burpeeBroadJump_time\" , \"rowErg_time\" , \"farmersCarry_time\" , \"sandbagLunges_time\" , \"wallBalls_time\" , ] field = race [ split_cols ] . astype ( float ) means = field . mean () stds = field . std ( ddof = 0 ) . replace ( 0 , np . nan ) z = ( field - means ) / stds race_z = pd . concat ([ race [[ \"name\" ]], z ], axis = 1 ) 2. Rank percentiles by total time \u00b6 race = client.get_race(season=7, location=\"london\") race = race.sort_values(\"total_time\") race[\"percentile\"] = race[\"total_time\"].rank(pct=True) 3. Create pace buckets \u00b6 bins = [0, 55, 60, 65, 70, 999] labels = [\"<55\", \"55-60\", \"60-65\", \"65-70\", \"70+\"] race[\"pace_bucket\"] = pd.cut(race[\"total_time\"], bins=bins, labels=labels) summary = race.groupby(\"pace_bucket\")[\"total_time\"].agg([\"count\", \"mean\"]) 4. Build a station share profile \u00b6 Identify which stations dominate a given athlete's time. athlete = client . get_athlete_in_race ( season = 7 , location = \"london\" , athlete_name = \"surname, name\" , ) split_cols = [ \"skiErg_time\", \"sledPush_time\", \"sledPull_time\", \"burpeeBroadJump_time\", \"rowErg_time\", \"farmersCarry_time\", \"sandbagLunges_time\", \"wallBalls_time\", ] row = athlete . iloc [ 0 ] share = row [ split_cols ] / row [ split_cols ] . sum ()","title":"Analytics"},{"location":"analytics/#analytics","text":"A focused set of workflows to extract signal from race data.","title":"Analytics"},{"location":"analytics/#1-segment-z-scores","text":"Normalize each station split relative to the field to see strengths and weaknesses. import numpy as np import pandas as pd race = client . get_race ( season = 7 , location = \"london\" , gender = \"male\" ) split_cols = [ \"skiErg_time\" , \"sledPush_time\" , \"sledPull_time\" , \"burpeeBroadJump_time\" , \"rowErg_time\" , \"farmersCarry_time\" , \"sandbagLunges_time\" , \"wallBalls_time\" , ] field = race [ split_cols ] . astype ( float ) means = field . mean () stds = field . std ( ddof = 0 ) . replace ( 0 , np . nan ) z = ( field - means ) / stds race_z = pd . concat ([ race [[ \"name\" ]], z ], axis = 1 )","title":"1. Segment z-scores"},{"location":"analytics/#2-rank-percentiles-by-total-time","text":"race = client.get_race(season=7, location=\"london\") race = race.sort_values(\"total_time\") race[\"percentile\"] = race[\"total_time\"].rank(pct=True)","title":"2. Rank percentiles by total time"},{"location":"analytics/#3-create-pace-buckets","text":"bins = [0, 55, 60, 65, 70, 999] labels = [\"<55\", \"55-60\", \"60-65\", \"65-70\", \"70+\"] race[\"pace_bucket\"] = pd.cut(race[\"total_time\"], bins=bins, labels=labels) summary = race.groupby(\"pace_bucket\")[\"total_time\"].agg([\"count\", \"mean\"])","title":"3. Create pace buckets"},{"location":"analytics/#4-build-a-station-share-profile","text":"Identify which stations dominate a given athlete's time. athlete = client . get_athlete_in_race ( season = 7 , location = \"london\" , athlete_name = \"surname, name\" , ) split_cols = [ \"skiErg_time\", \"sledPush_time\", \"sledPull_time\", \"burpeeBroadJump_time\", \"rowErg_time\", \"farmersCarry_time\", \"sandbagLunges_time\", \"wallBalls_time\", ] row = athlete . iloc [ 0 ] share = row [ split_cols ] / row [ split_cols ] . sum ()","title":"4. Build a station share profile"},{"location":"api/","text":"Client API \u00b6 PyroxClient \u00b6 Create a client: from pyrox import PyroxClient client = PyroxClient () list_races(season: int | None = None, force_refresh: bool = False) \u00b6 Return a DataFrame of available races. Filter by season when provided. get_race(...) \u00b6 get_race ( season : int , location : str , year : int | None = None , gender : str | None = None , division : str | None = None , total_time : float | tuple [ float | None , float | None ] | None = None , use_cache : bool = True , ) -> pd . DataFrame Key behaviors: - Applies server-side gender and division filters when available. - Converts time columns into minutes. - Supports strict time windows using total_time . Division values seen in the dataset include open , pro , and pro_doubles . get_athlete_in_race(...) \u00b6 get_athlete_in_race ( season : int , location : str , athlete_name : str , year : int | None = None , gender : str | None = None , division : str | None = None , use_cache : bool = True , ) -> pd . DataFrame Case-insensitive search on the name column. Raises AthleteNotFound if no match. get_season(...) \u00b6 get_season ( season : int , locations : Iterable [ str ] | None = None , gender : str | None = None , division : str | None = None , max_workers : int = 8 , use_cache : bool = True , ) -> pd . DataFrame Parallelized race fetching with a configurable worker pool. clear_cache(pattern: str = \"*\") \u00b6 Clear cached items matching a glob pattern. cache_info() -> dict \u00b6 Return cache statistics and keys.","title":"Client API"},{"location":"api/#client-api","text":"","title":"Client API"},{"location":"api/#pyroxclient","text":"Create a client: from pyrox import PyroxClient client = PyroxClient ()","title":"PyroxClient"},{"location":"api/#list_racesseason-int-none-none-force_refresh-bool-false","text":"Return a DataFrame of available races. Filter by season when provided.","title":"list_races(season: int | None = None, force_refresh: bool = False)"},{"location":"api/#get_race","text":"get_race ( season : int , location : str , year : int | None = None , gender : str | None = None , division : str | None = None , total_time : float | tuple [ float | None , float | None ] | None = None , use_cache : bool = True , ) -> pd . DataFrame Key behaviors: - Applies server-side gender and division filters when available. - Converts time columns into minutes. - Supports strict time windows using total_time . Division values seen in the dataset include open , pro , and pro_doubles .","title":"get_race(...)"},{"location":"api/#get_athlete_in_race","text":"get_athlete_in_race ( season : int , location : str , athlete_name : str , year : int | None = None , gender : str | None = None , division : str | None = None , use_cache : bool = True , ) -> pd . DataFrame Case-insensitive search on the name column. Raises AthleteNotFound if no match.","title":"get_athlete_in_race(...)"},{"location":"api/#get_season","text":"get_season ( season : int , locations : Iterable [ str ] | None = None , gender : str | None = None , division : str | None = None , max_workers : int = 8 , use_cache : bool = True , ) -> pd . DataFrame Parallelized race fetching with a configurable worker pool.","title":"get_season(...)"},{"location":"api/#clear_cachepattern-str","text":"Clear cached items matching a glob pattern.","title":"clear_cache(pattern: str = \"*\")"},{"location":"api/#cache_info-dict","text":"Return cache statistics and keys.","title":"cache_info() -&gt; dict"},{"location":"caching/","text":"Caching \u00b6 Pyrox caches results locally for speed and repeatability. Cache entries store the DataFrame plus metadata and ETags when available. Defaults \u00b6 Cache dir: ~/.cache/pyrox Manifest TTL: 2 hours Race TTL: 2 hours Season TTL: 1 hour Opt out per call \u00b6 race = client.get_race(season=7, location=\"london\", use_cache=False) Clear cache \u00b6 client.clear_cache() client.clear_cache(pattern=\"race_7_london*\") Inspect cache \u00b6 info = client.cache_info() print(info) Fields include cache_dir , total_items , total_size_mb , and cached keys.","title":"Caching"},{"location":"caching/#caching","text":"Pyrox caches results locally for speed and repeatability. Cache entries store the DataFrame plus metadata and ETags when available.","title":"Caching"},{"location":"caching/#defaults","text":"Cache dir: ~/.cache/pyrox Manifest TTL: 2 hours Race TTL: 2 hours Season TTL: 1 hour","title":"Defaults"},{"location":"caching/#opt-out-per-call","text":"race = client.get_race(season=7, location=\"london\", use_cache=False)","title":"Opt out per call"},{"location":"caching/#clear-cache","text":"client.clear_cache() client.clear_cache(pattern=\"race_7_london*\")","title":"Clear cache"},{"location":"caching/#inspect-cache","text":"info = client.cache_info() print(info) Fields include cache_dir , total_items , total_size_mb , and cached keys.","title":"Inspect cache"},{"location":"data-model/","text":"Data model \u00b6 Each race is returned as a pandas DataFrame where each row represents a single entry (athlete or doubles pair, depending on the race). Common columns \u00b6 Expect these columns in most races: name : athlete name as shown on the official results site. gender : male | female | mixed . division : open | pro | pro_doubles (case preserved as stored). total_time : total race time, minutes (float). work_time : total station time, minutes. roxzone_time : transition time, minutes. run_time : total running time, minutes. Station and run splits are normalized into readable names: skiErg_time sledPush_time sledPull_time burpeeBroadJump_time rowErg_time farmersCarry_time sandbagLunges_time wallBalls_time run1_time run2_time run3_time run4_time run5_time run6_time run7_time run8_time Time normalization \u00b6 All time columns are converted into minutes on load. Use them directly in statistical workflows without re-parsing. Schema drift \u00b6 The upstream data can evolve between seasons. Always check: print(df.columns) If a column is missing, adapt your pipeline rather than assuming it is always present.","title":"Data Model"},{"location":"data-model/#data-model","text":"Each race is returned as a pandas DataFrame where each row represents a single entry (athlete or doubles pair, depending on the race).","title":"Data model"},{"location":"data-model/#common-columns","text":"Expect these columns in most races: name : athlete name as shown on the official results site. gender : male | female | mixed . division : open | pro | pro_doubles (case preserved as stored). total_time : total race time, minutes (float). work_time : total station time, minutes. roxzone_time : transition time, minutes. run_time : total running time, minutes. Station and run splits are normalized into readable names: skiErg_time sledPush_time sledPull_time burpeeBroadJump_time rowErg_time farmersCarry_time sandbagLunges_time wallBalls_time run1_time run2_time run3_time run4_time run5_time run6_time run7_time run8_time","title":"Common columns"},{"location":"data-model/#time-normalization","text":"All time columns are converted into minutes on load. Use them directly in statistical workflows without re-parsing.","title":"Time normalization"},{"location":"data-model/#schema-drift","text":"The upstream data can evolve between seasons. Always check: print(df.columns) If a column is missing, adapt your pipeline rather than assuming it is always present.","title":"Schema drift"},{"location":"errors/","text":"Errors \u00b6 Pyrox exposes a small, predictable hierarchy so your pipelines can fail fast and recover gracefully. PyroxError \u00b6 Base class for client-specific errors. Catch this for broad error handling. RaceNotFound \u00b6 Raised when a season/location pair is missing from the manifest or a filter produces zero rows. AthleteNotFound \u00b6 Raised when the athlete name filter returns no matches. FileNotFoundError \u00b6 Raised when CDN reads fail unexpectedly. Consider retrying or logging the failing race metadata.","title":"Errors"},{"location":"errors/#errors","text":"Pyrox exposes a small, predictable hierarchy so your pipelines can fail fast and recover gracefully.","title":"Errors"},{"location":"errors/#pyroxerror","text":"Base class for client-specific errors. Catch this for broad error handling.","title":"PyroxError"},{"location":"errors/#racenotfound","text":"Raised when a season/location pair is missing from the manifest or a filter produces zero rows.","title":"RaceNotFound"},{"location":"errors/#athletenotfound","text":"Raised when the athlete name filter returns no matches.","title":"AthleteNotFound"},{"location":"errors/#filenotfounderror","text":"Raised when CDN reads fail unexpectedly. Consider retrying or logging the failing race metadata.","title":"FileNotFoundError"},{"location":"faq/","text":"FAQ \u00b6 Which seasons are covered? \u00b6 Historical coverage for seasons 2-7 (with season 5-6 being most used in analysis). Why are times in minutes? \u00b6 Times are normalized on load so your analysis can use numeric operations directly. How do I update cached data? \u00b6 Pass force_refresh=True to list_races or use_cache=False to any read method. Why does a race return empty? \u00b6 If a filter removes every row, RaceNotFound is raised. Try removing filters to confirm the base dataset exists.","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#which-seasons-are-covered","text":"Historical coverage for seasons 2-7 (with season 5-6 being most used in analysis).","title":"Which seasons are covered?"},{"location":"faq/#why-are-times-in-minutes","text":"Times are normalized on load so your analysis can use numeric operations directly.","title":"Why are times in minutes?"},{"location":"faq/#how-do-i-update-cached-data","text":"Pass force_refresh=True to list_races or use_cache=False to any read method.","title":"How do I update cached data?"},{"location":"faq/#why-does-a-race-return-empty","text":"If a filter removes every row, RaceNotFound is raised. Try removing filters to confirm the base dataset exists.","title":"Why does a race return empty?"},{"location":"filters/","text":"Filtering \u00b6 Pyrox supports high-signal filtering at read time, so you can load only the rows you need. Gender and division \u00b6 These filters are applied server-side for efficiency. race = client.get_race( season=7, location=\"london\", gender=\"male\", # \"male\" | \"female\" | \"mixed\" division=\"open\", # \"open\" | \"pro\" | \"pro_doubles\" ) Notes: - Values are case-sensitive in the underlying parquet filter; prefer lowercase. - If the filtered dataset has no rows, Pyrox raises RaceNotFound . Total time windows \u00b6 total_time is expressed in minutes. You can pass a single value or an open interval. # Under 60 minutes sub_60 = client.get_race(season=7, location=\"london\", total_time=60) # Open interval: 50 < total_time < 60 mid_pack = client.get_race(season=7, location=\"london\", total_time=(50, 60)) # Only lower bound slow = client.get_race(season=7, location=\"london\", total_time=(70, None)) Notes: - Bounds are strict ( > and < ), not inclusive. - Filtering happens after time columns are converted to minutes.","title":"Filtering"},{"location":"filters/#filtering","text":"Pyrox supports high-signal filtering at read time, so you can load only the rows you need.","title":"Filtering"},{"location":"filters/#gender-and-division","text":"These filters are applied server-side for efficiency. race = client.get_race( season=7, location=\"london\", gender=\"male\", # \"male\" | \"female\" | \"mixed\" division=\"open\", # \"open\" | \"pro\" | \"pro_doubles\" ) Notes: - Values are case-sensitive in the underlying parquet filter; prefer lowercase. - If the filtered dataset has no rows, Pyrox raises RaceNotFound .","title":"Gender and division"},{"location":"filters/#total-time-windows","text":"total_time is expressed in minutes. You can pass a single value or an open interval. # Under 60 minutes sub_60 = client.get_race(season=7, location=\"london\", total_time=60) # Open interval: 50 < total_time < 60 mid_pack = client.get_race(season=7, location=\"london\", total_time=(50, 60)) # Only lower bound slow = client.get_race(season=7, location=\"london\", total_time=(70, None)) Notes: - Bounds are strict ( > and < ), not inclusive. - Filtering happens after time columns are converted to minutes.","title":"Total time windows"},{"location":"quickstart/","text":"Quickstart \u00b6 Install \u00b6 Using uv: uv pip install -e . Or from PyPI: uv pip install pyrox-client Create a client \u00b6 import pyrox client = pyrox . PyroxClient () Discover races \u00b6 races = client.list_races(season=7) print(races.head()) Load a single race \u00b6 london = client.get_race( season=7, location=\"london\", gender=\"male\", division=\"open\", ) Load a season (parallelized) \u00b6 season7 = client.get_season(season=7, locations=[\"london\", \"barcelona\"]) Pull a specific athlete \u00b6 athlete = client.get_athlete_in_race( season=7, location=\"london\", athlete_name=\"surname, name\", ) Next \u00b6 See Filtering for precise time-window queries. See Data Model to understand columns and types. See Analytics and Reproducible Research for notes of race-analysis workflows.","title":"Getting Started"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#install","text":"Using uv: uv pip install -e . Or from PyPI: uv pip install pyrox-client","title":"Install"},{"location":"quickstart/#create-a-client","text":"import pyrox client = pyrox . PyroxClient ()","title":"Create a client"},{"location":"quickstart/#discover-races","text":"races = client.list_races(season=7) print(races.head())","title":"Discover races"},{"location":"quickstart/#load-a-single-race","text":"london = client.get_race( season=7, location=\"london\", gender=\"male\", division=\"open\", )","title":"Load a single race"},{"location":"quickstart/#load-a-season-parallelized","text":"season7 = client.get_season(season=7, locations=[\"london\", \"barcelona\"])","title":"Load a season (parallelized)"},{"location":"quickstart/#pull-a-specific-athlete","text":"athlete = client.get_athlete_in_race( season=7, location=\"london\", athlete_name=\"surname, name\", )","title":"Pull a specific athlete"},{"location":"quickstart/#next","text":"See Filtering for precise time-window queries. See Data Model to understand columns and types. See Analytics and Reproducible Research for notes of race-analysis workflows.","title":"Next"},{"location":"reproducible-research/","text":"Reproducible research \u00b6 This guide documents the workflow for the notebook example_notebooks/impact_of_race_locations.ipynb . The goal is to make results repeatable, auditable, and easy to refresh. What the notebook does \u00b6 Pulls Season 7 Open Singles data. Cleans and filters timing fields. Compares event distributions for total/work time by gender. Fits a regression with event-level interaction effects. Produces plots to visualize event differences. Dependencies \u00b6 The notebook relies on: pyrox-client pandas , numpy matplotlib , seaborn statsmodels If you are using uv (recommended): uv pip install -e . If you do not already have Jupyter installed: uv pip install jupyter Run the notebook \u00b6 From the repo root: uv run jupyter notebook example_notebooks/impact_of_race_locations.ipynb Alternative: uv run jupyter lab Then open the notebook and run cells top to bottom. Data determinism \u00b6 The notebook pulls from the live CDN. To keep results stable across runs: Avoid force_refresh=True unless you intend to refresh the dataset. Keep cached data between runs. Default cache location is ~/.cache/pyrox . If you need a clean refresh, clear the cache before running: python - << 'PY' import pyrox client = pyrox . PyroxClient () client . clear_cache () PY Inputs and outputs \u00b6 Inputs: - Season 7 race data ( get_season(season=7, division=\"open\") ). - Event list in events_to_analyse . Outputs: - Plots in the event_dists/ directory (created automatically). - Regression summary in the notebook output. Repro tips \u00b6 Keep a copy of the events_to_analyse list in the notebook output so the exact event set is recorded. If you publish results, consider exporting the dataset to a dated parquet file to preserve the snapshot used for modeling.","title":"Reproducible Research"},{"location":"reproducible-research/#reproducible-research","text":"This guide documents the workflow for the notebook example_notebooks/impact_of_race_locations.ipynb . The goal is to make results repeatable, auditable, and easy to refresh.","title":"Reproducible research"},{"location":"reproducible-research/#what-the-notebook-does","text":"Pulls Season 7 Open Singles data. Cleans and filters timing fields. Compares event distributions for total/work time by gender. Fits a regression with event-level interaction effects. Produces plots to visualize event differences.","title":"What the notebook does"},{"location":"reproducible-research/#dependencies","text":"The notebook relies on: pyrox-client pandas , numpy matplotlib , seaborn statsmodels If you are using uv (recommended): uv pip install -e . If you do not already have Jupyter installed: uv pip install jupyter","title":"Dependencies"},{"location":"reproducible-research/#run-the-notebook","text":"From the repo root: uv run jupyter notebook example_notebooks/impact_of_race_locations.ipynb Alternative: uv run jupyter lab Then open the notebook and run cells top to bottom.","title":"Run the notebook"},{"location":"reproducible-research/#data-determinism","text":"The notebook pulls from the live CDN. To keep results stable across runs: Avoid force_refresh=True unless you intend to refresh the dataset. Keep cached data between runs. Default cache location is ~/.cache/pyrox . If you need a clean refresh, clear the cache before running: python - << 'PY' import pyrox client = pyrox . PyroxClient () client . clear_cache () PY","title":"Data determinism"},{"location":"reproducible-research/#inputs-and-outputs","text":"Inputs: - Season 7 race data ( get_season(season=7, division=\"open\") ). - Event list in events_to_analyse . Outputs: - Plots in the event_dists/ directory (created automatically). - Regression summary in the notebook output.","title":"Inputs and outputs"},{"location":"reproducible-research/#repro-tips","text":"Keep a copy of the events_to_analyse list in the notebook output so the exact event set is recorded. If you publish results, consider exporting the dataset to a dated parquet file to preserve the snapshot used for modeling.","title":"Repro tips"}]}